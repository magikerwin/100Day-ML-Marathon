# 100 days of machine learning code challenge

### 1. 資料清理數據前處理
* Day001： 資料分析與評估
* Day002： EDA - Data summary
* Day003： EDA - Pandas Dataframe
* Day004： EDA - 欄位的資料類型介紹及處理
* Day005： EDA - 資料分佈
* Day006： EDA - Outlier 及處理
* Day007： EDA - 常用的數值取代：中位數與分位數連續數值標準化
* Day008： EDA - Pandas DataFrame operationDat/frame merge
* Day009： EDA - correlation/相關係數簡介
* Day010： EDA - from Correlation
* Day011： EDA - Kernel Density Estimation (KDE)
* Day012： EDA - 把連續型變數離散化
* Day013： EDA - 把連續型變數離散化 實作
* Day014： Subplots
* Day015： Heatmap & Grid-plot
* Day016： 模型初體驗 Logistic Regression

### 2. 資料科學特徵工程技術
* Day017： 特徵工程簡介
* Day018： 特徵類型
* Day019： 數值型特徵-補缺失值與標準化
* Day020： 數值型特徵 - 去除離群值
* Day021： 數值型特徵 - 去除偏態
* Day022： 類別型特徵 - 基礎處理
* Day023： 類別型特徵 - 均值編碼
* Day024： 類別型特徵 - 其他進階處理
* Day025： 時間型特徵
* Day026： 特徵組合 - 數值與數值組合
* Day027： 特徵組合 - 類別與數值組合
* Day028： 特徵選擇
* Day029： 特徵評估
* Day030： 分類型特徵優化 - 葉編碼

### 3. 機器學習基礎模型建立
* Day031： 機器學習概論
* Day032： 機器學習-流程與步驟
* Day033： 機器如何學習?
* Day034： 訓練/測試集切分的概念
* Day035： regression vs. classification
* Day036： 評估指標選定/evaluation metrics
* Day037： regression model 介紹 - 線性迴歸/羅吉斯回歸
* Day038： regression model 程式碼撰寫
* Day039： regression model 介紹 - LASSO 回歸/ Ridge 回歸
* Day040： regression model 程式碼撰寫
* Day041： tree based model - 決策樹 (Decision Tree) 模型介紹
* Day042： tree based model - 決策樹程式碼撰寫
* Day043： tree based model - 隨機森林 (Random Forest) 介紹
* Day044： tree based model - 隨機森林程式碼撰寫
* Day045： tree based model - 梯度提升機 (Gradient Boosting Machine) 介紹
* Day046： tree based model - 梯度提升機程式碼撰寫

### 4. 機器學習調整參數
* Day047： Hyperparameter Tuning
* Day048： Kaggle introduction
* Day049： Ensemble Learning - 混合泛化(Blending)
* Day050： Ensemble Learning - 堆疊泛化(Stacking)

### Kaggle 期中考
* Day051： Kaggle Midterm Exam
* Day052： Kaggle Midterm Exam
* Day053： Kaggle Midterm Exam

### 5. 非監督式學習
* Day054： clustering 1 非監督式機器學習簡介
* Day055： clustering 2 聚類算法
* Day056： K-mean 觀察 - 使用輪廓分析
* Day057： clustering 3 階層分群算法
* Day058： 階層分群法 - 使用 2D 樣版資料集
* Day059： dimension reduction 1 降維方法-主成份分析
* Day060： PCA 觀察 - 使用手寫辨識資料集.
* Day061： dimension reduction 2 降維方法-T-SNE
* Day062： t-sne 觀察 - 分群與流形還原

### 6. 深度學習理論與實作
* Day063： 神經網路介紹
* Day064： 深度學習體驗 - 模型調整與學習曲線
* Day065： 深度學習體驗 - 啟動函數與正規化

### 7. 初探深度學習使用Keras
* Day066： Keras installation
* Day067： Keras Dataset
* Day068： Keras Sequential API
* Day069： Keras Module API
* Day070： Multi-layer Perception
* Day071： Loss Function
* Day072： Activation Function
* Day073： Gradient Descent
* Day074： Gradient Descent
* Day075： Back Propagation
* Day076： Optimizer
* Day077： Validation & Overfit
* Day078： Training Tip
* Day079： Learning Rate
* Day080： Keras pratice - Optimizer/Learning Rate
* Day081： Regularization
* Day082： Dropout
* Day083： BatchNorm
* Day084： Keras pratice - Regularization/Dropout/BatchNorm
* Day085： Keras callbacks & earlystop